# voice-conversion

* This code is an implementation of AutoVC paper and the paper i referred to understand was
    * [https://arxiv.org/abs/1905.05879]


*  The codes which i referred are following:
   * https://auspicious3000.github.io/icassp-2020-demo/
   * https://github.com/auspicious3000/autovc


 ***Style Encoder***:
* Referred to the speaker encoder used in 
    *https://github.com/CODEJIN/Speaker_Embedding_Torch and fine tuned it on my data. The model weights are loaded in the checkpoints folder

***Content Encoder and Decoder***:
   * Referred to the architecture in the paper and the codes and fintuned it on my data and trained again

 ***Results***:
  *  Results are stored in results/ folder


